##################################class#######################################


class ANN_singal_layer():
    
    import pandas as pd
    import numpy as np


    def forward(X, W1, b1, W2, b2):
        Z = 1 / (1 + np.exp(-X.dot(W1) - b1))
        A = Z.dot(W2) + b2
        expA = np.exp(A)
        Y = expA / expA.sum(axis=1, keepdims=True)
        return Y, Z


    def classification_rate(Y, P):
        n_correct = 0
        n_total = 0
        for i in range(len(Y)):
            n_total += 1
            if Y[i] == P[i]:
                n_correct += 1
        return float(n_correct) / n_total


    def derivative_w2(Z, T, Y):
        N, K = T.shape
        M = Z.shape[1] 
        ret4 = Z.T.dot(T - Y)
        return ret4


    def derivative_w1(X, Z, T, Y, W2):
        N, D = X.shape
        M, K = W2.shape
        dZ = (T - Y).dot(W2.T) * Z * (1 - Z)
        ret2 = X.T.dot(dZ)
        return ret2


    def derivative_b2(T, Y):
        return (T - Y).sum(axis=0)


    def derivative_b1(T, Y, W2, Z):
        return ((T - Y).dot(W2.T) * Z * (1 - Z)).sum(axis=0)


#     def cost(T, Y):
#         tot = T * np.log(Y)
#         return tot.sum()


    def fit(X,Y,M=2):

        N, D = X.shape
        K=len(np.unique(Y))

        if isinstance(X,pd.core.frame.DataFrame) or isinstance(X,pd.core.series.Series):
            X=X.values
        if isinstance(Y,pd.core.frame.DataFrame) or isinstance(Y,pd.core.series.Series):
            Y=Y.values

        # Vectorizing target variables
        N = len(Y)
        T = np.zeros((N, K))
        for i in range(N):
            T[i, Y[i]] = 1

        # randomly initialize weights
        W1 = np.random.randn(D, M)
        b1 = np.random.randn(M)
        W2 = np.random.randn(M, K)
        b2 = np.random.randn(K)

        learning_rate = 1e-3
        for epoch in range(140):
            output, hidden = forward(X, W1, b1, W2, b2)
            W2 += learning_rate * derivative_w2(hidden, T, output)
            b2 += learning_rate * derivative_b2(T, output)
            W1 += learning_rate * derivative_w1(X, hidden, T, output, W2)
            b1 += learning_rate * derivative_b1(T, output, W2, hidden)

        return([W1, b1, W2, b2])

    def predict(X,V):
        W1, b1, W2, b2=V
        Z = 1 / (1 + np.exp(-X.dot(W1) - b1))
        A = Z.dot(W2) + b2
        expA = np.exp(A)
        Y = expA / expA.sum(axis=1, keepdims=True)
        return Y
















####################################Testing Function#############################


Nclass = 500
D = 2 # dimensionality of input
M = 3 # hidden layer size
K = 2 # number of classes

X1 = np.random.randn(Nclass, D) + np.array([0, -2])
X2 = np.random.randn(Nclass, D) + np.array([2, 2])

X = np.vstack([X1, X2])

Y = np.array([0]*Nclass + [1]*Nclass )
ZZ=ANN_singal_layer.fit(X,Y)
ANN_singal_layer.predict(X,ZZ)

####################################################################################